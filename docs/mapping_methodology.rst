Mapping Methodology
===================
..
   Incorporate Methodology notes from Confluence

The Sensor Mapping to ATT&CK project links event values in sensors and log files to ATT&CK Enterprise Data Sources. The resultant mappings can be used to either take a sensor event value and determine associated ATT&CK techniques and sub-techniques, or to take an ATT&CK technique or sub-techniques and compose a list of associated sensor events. This methodology describes the scope of this project and the process used to map events native to a technology platform to ATT&CK Data Sources, and aims to provide the community a reusable method of using ATT&CK to determine the capabilities of a platform's security offerings.

MITRE ATT&CK® is a globally-accessible knowledge base of adversary
tactics and techniques based on real-world observations. ATT&CK focuses
on how external adversaries compromise and operate within computer
information networks. ATT&CK describes adversary behaviors using the following core
components:

-  **Tactics:** "why" - the adversary's objective or reason for
   performing an action

-  **Techniques:** "how" - the means by which adversaries achieve
   tactical goals

-  **Sub-techniques:** describing more specific means by which
   adversaries achieve tactical goals at a lower level than techniques

-  **Data Source:** source of information collected by a sensor or logging system that may be used to collect information relevant to identifying the action being performed, sequence of actions, or the results of those actions by an adversary

-  **Data Component:** any constituent pieces of the data source, which are best described separately. Components may have their own set of metadata (describing the associated fields/values associated with the source) and activities (describing actions of the source).

**Data Elements:** names, definitions, and attributes that are being used or captured in an event

**Sensors:** an agent or service capable of detecting or measuring information across many different sources on a host in real-time and providing raw data with high precision and accuracy 

**Telemetry/Events:** generated by sensors in the form of log data, regardless of the format (e.g., json, csv, etc.), as long as the data is automatically generated and transmitted or streamed in near real-time


Scope
-----

Scoping for this project is focused on mappings for the following security logs, sensors, and capabilities:

- Windows Security Events
- Sysmon
- Auditd
- CloudTrail
- OSQuery
- ZEEK

..
   Expand this section. Consider explaining event scope here as well (from step 1 below).

Mapping Philosophy and Process
------------------------------
..
   Develop graphic for this section.

Mappings are created by analyzing each in-scope event log/sensor in relation to ATT&CK Data Sources. Sensors/log files and ATT&CK are at different levels of abstraction and cannot always perfectly detect the adversary behaviors that they are meant to represent. Some amount of analyst judgement is required and, whenever judgement is involved, there can be differences in opinion. These design decisions document our judgement and rationale.

The methodology consists of the following steps:

- **Identify Platform Events/Telemetry** - Identify the *native* event logs available on the platform.
- **Description Correlation** - For each identified event, understand the security capabilities it provides.
- **Relationship Correlation** - Identify the ATT&CK Data Sources mappable to event IDs.
- **Telemetry Source Correlation** - Creating a mapping based on the information gathered from the previous steps. 

Adversary behaviors can be described by mapping them to the appropriate tactics, techniques, and sub-techniques in ATT&CK. To detect these behaviors, ATT&CK has a detection section that maps directly to the collection source (data sources). 

`ATT&CK's Data Sources <http://attack.mitre.org/datasources/>`_ usually fall into one of the following buckets: 

- Granular basic system artifacts (e.g., process, file, registry)
- Granular basic user activities (e.g., logon session)
- Abstract types of system artifacts, with children as sub-types (e.g., scheduled jobs)
- Associated network traffic (e.g., wmi and registry), in such cases, it's important to capture the set of protocols that encompasses this traffic, so that users may understand where they need to look in their logs/PCAPs/DPI appliances/etc.

After understanding the capabilities of the event ID and gathering the basic facts about its operation, as identified in the previous step, review the ATT&CK matrix and identify the data source the event is able to detect. 


Step 1:  Identify Platform Events/Telemetry
-------------------------------------------

Sensors/Tools generate logs of real-time data that is indicative of a sequence of actions conducted by the user of a computer system. With those actions having a potential to inform a defender of adversary activity, this is the first location to look for further evidence. Typically, Sensors can be broken out into 2 categories: 

**Host:** data gathered from endpoints in the environment (e.g., Windows, MacOS, Linux)
   
   - Examples: 
      - Windows Event Logs
      - Sysmon
      - OSQuery
      - EDR Products (Carbon Black, Crowdstrike, Microsoft Defender ATP, etc.)
      - Services, Processes, Command-lines, Loaded Modules, DLLs
      - Files, Registry
      - Scheduled Tasks, Cron Jobs, Launch Agents
      - User Account, Hardware Info
      - Memory Data 

**Network:** data gathered from network communications, typically outbound connections

   - Examples: 
      - Firewall Logs
      - Proxy Logs
      - IDS/IPS Logs
      - Netflow Data 
      - Bro/Zeek
      - Packet Capture


Sensor documentation on the security capabilities of each platform (e.g., security reference architectures, security benchmarks, security documentation of various services) is reviewed to identify event IDs offered by the platform for detecting workloads on the platform. 

Keep the following in mind while selecting event IDs:

- The scope of the events mapped by this project is telemetry that can be collected by a sensor or logging system that may be used to collect information relevant to identifying the action being performed, sequence of actions, or the results of those actions by an adversary. 
- The selected events should be native to the platform, i.e., produced by the operating system themselves. For example, event IDs developed directly in a third-party tool are considered out of scope.
- The event IDs selected to be mapped as part of this project tend to be events that are marketed as native and made available on the platform. The intent is not to provide a mapping for all settings/features of individual platform services that are security related. This is a non-trivial undertaking that may be explored at a later time.


Step 2: Description Correlation
-------------------------------

What makes sensors useful to defenders is the meaning and context associated with the event. For each identified event ID, consult the available documentation to understand its capabilities. Gather specific facts about the event ID that will later help in mapping the event to the set of ATT&CK Data Sources it is able to detect. 

The most common way to bring context to the event is by applying the description and other types of metadata (Data Elements/Fields). When documented the description, elements, and fields can help us understand what the sensor is truly capturing, and make creating detections more efficient.

Identify the Source of Data 
***************************

Start with **identifying the source of data**. In a Windows environment, we can collect information pertaining to "Processes" from built-in event providers such as Microsoft-Windows-Security-Auditing and open third-party tools, including Sysmon. 

.. image:: _static/WSE.png
   :width: 600

Think about the questions below for additional context on potential source of the data. 

- *why were these security events generated in my environment? (Activity)*
- *what operating system supports its generation? (Platform)*

Example: Let's use security event 4688: A new process has been created provided by Microsoft Windows security auditing as a basic example to understand this step of the methodology. 

- The action that triggered the generation of this event was the creation of a new process (Activity). 
- This security event can be collected by using the built-in event logging application for devices that work with the Windows operating system (Platform). Within a Windows environment, it is typically known to have a "process" as a source of data that. 


Lets look at Sysmon EID 1, Sysmon EID 8, WinEvtx 4688, and WinEvtx 4696. The image below shows that the definition all have some correlation with either starting or executing a process. 

.. image:: _static/DEF3.png
   :width: 700

This step also takes into account the overall event where a process can be represented as the main data element around an adversary action. This could include actions such as a process connected to an IP address, modifying a registry, or creating a file.

Step 3: Relationship Correlation
--------------------------------

Identify the Data Element
*************************

Next in reviewing the event ID, **identify the data element**. Once we identify and understand more about sources of data that can be mapped to an ATT&CK data source, we can start identifying data elements within the event fields that could help us eventually represent adversary behavior from a data perspective. 

The use of Data Elements help to name ATT&CK Data Sources related to the adversary behavior. For example, if an adversary modifies a Windows Registry value, collection of Windows Registry telemetry is needed. **How the adversary modified the registry, such as the process or user that performed the action, is how we pinpoint the data elements.** Below continuing on with our process example. As we think about how an adversary can create a process we are left with process, user, command, and thread. 

.. image:: _static/DE3.png
   :width: 700

Identifying the main data object to collect data from and/or all the data objects that define the context of the source of data is a method that can also be applied. This method can also be used to provide a general idea of what is needed to be collected. For example, data elements that provide metadata about network traffic can be grouped together and be associated with Netflow.

.. image:: _static/DE2.png
   :width: 600

The image below displays how we can extend the concept of an event log and capture the data elements featured within it. 

.. image:: _static/DE5.png
   :width: 600


There is a fundamental rule that should be considered when defining: **there is no one correct way to define data elements**. Please look to your organizational needs to help define what data elements means to you.

Identify Relationships among Data Elements
******************************************

By documenting the event collection, source (creation of a new process), and data elements (user account and process), we can start describing **interactions among elements through relationships**. Relationships in ATT&CK have been categorized between *activity* and *information*. Activity relationships are the ones that make references to the action that triggered the generation of the event. Informational relationships are the ones defined based on the metadata provided by the event. 

.. image:: _static/RDE1.png
   :width: 600

As the groupings grow, the similarities appear where different platforms or sensors tend to link to the same ATT&CK Data Source. 

.. image:: _static/RDE4.png
   :width: 600

As discussed by `OSSEM <https://github.com/OTRF/OSSEM>`_ at their ATT&CKcon 2018 and 2019 presentation. The activity of the relationship leads to Data Components. Data Components will help us to categorize relationships among data elements based on the security context they describe (i.e. Creation, Execution, Deletion). 

.. image:: _static/RDE5.png
   :width: 700

Note: Pay attention to the differences between similar data sources and events. Two events with the same field names can represent different data. For example, process data collected from Sysmon 1, Windows Event 4688, and/or Windows Event 4696 could provide visibility into behaviors associated with T1134: Access Token Manipulation. But when looking for T1543: Create or Modify System Process, data should not be collected from Windows Event 4696 to prove adversary activity as this technique does not involve the use of system tokens. The following visuals are provided to help illustrate this example:

.. image:: _static/T1543EX.png
   :width: 600

.. image:: _static/T1134EX.png
   :width: 600
   


Step 4: Telemetry Source Correlation 
---------------------------------------------

This is by far the hardest level to find for correlation because at times it requires some reverse engineering. `OSSEM <https://github.com/OTRF/OSSEM>`_, `Telemetry Source <https://github.com/jsecurity101/TelemetrySource>`_, and other open source research projects do a good job of explaining how they approach this process. 

..
   Fill in the rest for this correlation piece : Identifying Telemetry Source (ETW/Kernal Callbacks/APIs/etc.)
 

